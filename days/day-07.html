<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Day 7 of 100 Days of CUDA - one_d_convolution.cu">
    <meta name="theme-color" content="#4361ee">
    <title>Day 7: one_d_convolution.cu - 100 Days of CUDA</title>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="../css/styles.css">
    <link rel="shortcut icon" href="../assets/favicon.svg" type="image/svg+xml">
    <style>
        /* Add specific styles for code display */
        pre {
            background-color: var(--code-bg);
            padding: 1rem;
            border-radius: 4px;
            overflow-x: auto;
        }
        
        code {
            font-family: 'Consolas', 'Monaco', 'Courier New', monospace;
            font-size: 0.9rem;
            color: var(--text-color);
        }
        
        h2, h3, h4 {
            color: var(--primary-color);
            margin-top: 1.5rem;
        }
        
        ul, ol {
            padding-left: 2rem;
            margin-bottom: 1rem;
        }
        
        li {
            margin-bottom: 0.5rem;
        }
        
        a {
            color: var(--primary-color);
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        @media (max-width: 768px) {
            pre, code {
                font-size: 0.85rem;
            }
            
            h2 {
                font-size: 1.5rem;
            }
            
            h3 {
                font-size: 1.3rem;
            }
            
            h4 {
                font-size: 1.1rem;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <header>
            <div class="header-content">
                <h1><a href="../index.html" style="text-decoration: none; color: inherit;">100 Days of CUDA</a></h1>
                <button id="theme-toggle" aria-label="Toggle dark/light mode">
                    <span class="theme-icon"></span>
                </button>
            </div>
        </header>
        
        <div class="content-wrapper">
            <aside class="sidebar">
                <div class="sidebar-header">
                    <h2>Days</h2>
                    <button id="mobile-menu-toggle" aria-label="Toggle menu">
                        <span class="menu-icon"></span>
                    </button>
                </div>
                <nav id="days-navigation">
                    <!-- Day links will be generated here -->
                    <div class="days-list-placeholder">Loading...</div>
                </nav>
            </aside>
            
            <main>
                <!-- Day content -->
                <div class="day-content">
                    <h2>Day 7</h2><h3>File: `one_d_convolution.cu`</h3><h4>Summary:</h4><p>Implemented a simple 1D convolution algorithm using CUDA. This involved sliding a kernel (or filter) over an input array and computing the weighted sum of elements. Each thread was assigned to compute the convolution at a specific position in the output array.  </p><br><h4>Learned:</h4><ul><li>Basics of 1D convolution in parallel, including mapping threads to positions in the output array.</li><li>How to handle boundary conditions (halo cells) when the kernel partially overlaps the input array bounds.</li><li>Importance of memory layout and contiguous access for kernel weights and input arrays to maximize performance.</li></ul><br><hr><br><h3>File: `one_d_convolution_with_tiling.cu`</h3><h4>Summary:</h4><p>Implemented an optimized version of the 1D convolution algorithm using tiling and shared memory. Divided the input array into tiles and loaded data into shared memory, minimizing global memory accesses for better performance. Used halo cells to handle edge cases where kernel overlap extended into neighboring tiles.  </p><br><h4>Learned:</h4><ul><li>Tiling in CUDA: Dividing input data into manageable chunks and leveraging shared memory to reduce global memory latency.</li><li>Use of **halo cells** to ensure correctness at tile boundaries during convolution.</li><li>How to balance computation and memory usage in tiled algorithms to improve performance.</li><li>Proper synchronization of threads within a block (using `__syncthreads()`) to ensure data consistency in shared memory.</li></ul><br><hr><h3>File: `2d_convolution_with_tiling.cu`  </h3><h4>Summary:</h4><p>Implemented a 2D convolution algorithm with tiling optimization using CUDA. Divided the input matrix into tiles and leveraged shared memory to minimize global memory accesses, ensuring efficient computation of the convolution kernel across the matrix. Handled boundary conditions using halo cells to process edges and corners correctly.  </p><br><h4>Learned:</h4><ul><li>Extended tiling techniques from 1D to 2D data structures for efficient parallel computation.  </li><li>Optimized global memory access by using shared memory for each tile.  </li><li>Synchronization of threads for consistent shared memory usage within a block (`__syncthreads()` for proper execution order).  </li><li>Efficient handling of edge cases and boundary cells in 2D convolution.  </li></ul><br><hr><br><h3>Reading:  </h3><li>Read **Chapter 7** of the PMPP book.  </li><li style="margin-left: 20px;">Learned about parallel patterns for convolution, including basic algorithms, memory optimizations with constant and shared memory, and tiling techniques with halo cells for 1D and 2D convolution.</li>
                </div>
            </main>
        </div>
        
        <footer>
            <p>&copy; <span id="current-year"></span> 100 Days of CUDA</p>
        </footer>
    </div>
    
    <script src="../js/app.js"></script>
</body>
</html>